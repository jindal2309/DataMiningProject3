{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx7EsK3JZcN5",
        "colab_type": "text"
      },
      "source": [
        "# Project 3 : Multi-label Image Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRk3S1quZxoA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ee63ef8-d5d3-40aa-f966-8e88ca7ab5c2"
      },
      "source": [
        "# Supress unnecessary warnings so that presentation looks clean\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Google Colab stuff\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6gQPQQMZ9lA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a5dc690-b5be-4bc4-b52c-78896bc5ba4b"
      },
      "source": [
        "cd '/content/drive/My Drive/Colab Notebooks/DM_project3/Assignment3_p1'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/DM_project3/Assignment3_p1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXvcd8HwZcN8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "efe3ed34-27bf-4448-a080-6a32fe778241"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import average_precision_score\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR3qcYFMeqy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import random\n",
        "import os, numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "from scipy.misc import imread, imresize\n",
        "from skimage.transform import resize\n",
        "from scipy.sparse import csr_matrix\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "VOC_CLASSES = ('__background__', 'aeroplane', 'bicycle', 'bird', 'boat',\n",
        "                        'bottle', 'bus', 'car', 'cat', 'chair',\n",
        "                        'cow', 'diningtable', 'dog', 'horse',\n",
        "                        'motorbike', 'person', 'pottedplant',\n",
        "                        'sheep', 'sofa', 'train', 'tvmonitor')\n",
        "\n",
        "\n",
        "class VocDataset(data.Dataset):\n",
        "    def __init__(self, data_path, dataset_split, transform, random_crops=0):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "        self.random_crops = random_crops\n",
        "        self.dataset_split = dataset_split\n",
        "\n",
        "        self.__init_classes()\n",
        "        self.names, self.labels, self.box_indices, self.label_order = self.__dataset_info()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = imread(self.data_path + '/JPEGImages/' + self.names[index] + '.jpg', mode='RGB')\n",
        "        x = Image.fromarray(x)\n",
        "\n",
        "        scale = np.random.rand() * 2 + 0.25\n",
        "        w = int(x.size[0] * scale)\n",
        "        h = int(x.size[1] * scale)\n",
        "        if min(w, h) < 227:\n",
        "            scale = 227 / min(w, h)\n",
        "            w = int(x.size[0] * scale)\n",
        "            h = int(x.size[1] * scale)\n",
        "\n",
        "        if self.random_crops == 0:\n",
        "            x = self.transform(x)\n",
        "        else:\n",
        "            crops = []\n",
        "            for i in range(self.random_crops):\n",
        "                crops.append(self.transform(x))\n",
        "            x = torch.stack(crops)\n",
        "\n",
        "        y = self.labels[index]\n",
        "        z = self.box_indices[index]\n",
        "        return x, y, z\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __init_classes(self):\n",
        "        self.classes = VOC_CLASSES\n",
        "        self.num_classes = len(self.classes)\n",
        "        self.class_to_ind = dict(zip(self.classes, range(self.num_classes)))\n",
        "\n",
        "    def __dataset_info(self):\n",
        "        with open(self.data_path + '/ImageSets/Main/' + self.dataset_split + '.txt') as f:\n",
        "            annotations = f.readlines()\n",
        "\n",
        "        annotations = [n[:-1] for n in annotations]\n",
        "        box_indices = []\n",
        "        names = []\n",
        "        labels = []\n",
        "        label_order = []\n",
        "        for af in annotations:\n",
        "            if len(af) != 6:\n",
        "                continue\n",
        "            filename = os.path.join(self.data_path, 'Annotations', af)\n",
        "            tree = ET.parse(filename + '.xml')\n",
        "            objs = tree.findall('object')\n",
        "            num_objs = len(objs)\n",
        "\n",
        "            boxes = np.zeros((num_objs, 4), dtype=np.int32)\n",
        "            boxes_cl = np.zeros((num_objs), dtype=np.int32)\n",
        "            boxes_cla = []\n",
        "            temp_label = []\n",
        "            for ix, obj in enumerate(objs):\n",
        "                bbox = obj.find('bndbox')\n",
        "                # Make pixel indexes 0-based\n",
        "                x1 = float(bbox.find('xmin').text) - 1\n",
        "                y1 = float(bbox.find('ymin').text) - 1\n",
        "                x2 = float(bbox.find('xmax').text) - 1\n",
        "                y2 = float(bbox.find('ymax').text) - 1\n",
        "\n",
        "                cls = self.class_to_ind[obj.find('name').text.lower().strip()]\n",
        "                boxes[ix, :] = [x1, y1, x2, y2]\n",
        "                boxes_cl[ix] = cls\n",
        "                boxes_cla.append(boxes[ix, :])\n",
        "                temp_label.append(cls)\n",
        "\n",
        "            lbl = np.zeros(self.num_classes)\n",
        "            lbl[boxes_cl] = 1\n",
        "            labels.append(lbl)\n",
        "            names.append(af)\n",
        "            box_indices.append(boxes_cla)\n",
        "            label_order.append(temp_label)\n",
        "\n",
        "        return np.array(names), np.array(labels).astype(np.float32), np.array(box_indices), label_order\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHIPDLmAZcOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transforms applied to the training data\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std= [0.229, 0.224, 0.225])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "            transforms.Resize(227),\n",
        "            transforms.CenterCrop(227),\n",
        "            transforms.ToTensor(),\n",
        "            normalize\n",
        "        ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJYhDzqxZcOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_train = VocDataset('VOCdevkit_2007/VOC2007/','train',train_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC212t0nZcOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transforms applied to the testing data\n",
        "test_transform = transforms.Compose([\n",
        "            transforms.Resize(227),\n",
        "            transforms.CenterCrop(227),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak1FClxmZcOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_val = VocDataset('VOCdevkit_2007/VOC2007/','val',test_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F94FEebPeO4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I7RpNxpeawS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import numpy as np\n",
        "\n",
        "NUM_CLASSES = 21\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
        "        self.conv2 = nn.Conv2d(64, 32, 3)\n",
        "        self.conv3 = nn.Conv2d(32, 16, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 26 * 26, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, NUM_CLASSES)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(x.size()[0], 16 * 26 * 26)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr5JGK7JZcOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myG56qvrZcOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=ds_train,\n",
        "                                               batch_size=50, \n",
        "                                               shuffle=True,\n",
        "                                               num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytg6Fr8MZcOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(dataset=ds_val,\n",
        "                                               batch_size=50, \n",
        "                                               shuffle=True,\n",
        "                                               num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0kCeDC4ZcOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_classifier(train_loader, classifier, criterion, optimizer):\n",
        "    classifier.train()\n",
        "    loss_ = 0.0\n",
        "    losses = []\n",
        "    for i, (images, labels, _) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = classifier(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss)\n",
        "    return torch.stack(losses).mean().item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPgmMsbMZcOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_classifier(test_loader, classifier, criterion, print_ind_classes=True):\n",
        "    classifier.eval()\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        y_true = np.zeros((0,21))\n",
        "        y_score = np.zeros((0,21))\n",
        "        for i, (images, labels, _) in enumerate(test_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            logits = classifier(images)\n",
        "            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n",
        "            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n",
        "            loss = criterion(logits, labels)\n",
        "            losses.append(loss)\n",
        "        aps = []\n",
        "        # ignore first class which is background\n",
        "        for i in range(1, y_true.shape[1]):\n",
        "            ap = average_precision_score(y_true[:, i], y_score[:, i])\n",
        "            if print_ind_classes:\n",
        "                print('-------  Class: {:<12}     AP: {:>8.4f}  -------'.format(VOC_CLASSES[i], ap))\n",
        "            aps.append(ap)\n",
        "        \n",
        "        mAP = np.mean(aps)\n",
        "        test_loss = np.mean(losses)\n",
        "        print('mAP: {0:.4f}'.format(mAP))\n",
        "        print('Avg loss: {}'.format(test_loss))\n",
        "        \n",
        "    return mAP, test_loss, aps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ygk5j_hZcOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "afec4b19-1106-4d83-aa32-c81d9734f3ce"
      },
      "source": [
        "classifier = Classifier().to(device)\n",
        "# You can can use this function to reload a network you have already saved previously\n",
        "#classifier.load_state_dict(torch.load('voc_classifier.pth'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-934616731ea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# You can can use this function to reload a network you have already saved previously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#classifier.load_state_dict(torch.load('voc_classifier.pth'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwzALw-nZcO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "7f0df0eb-9d76-42a0-8605-fa0690ea6cb2"
      },
      "source": [
        "criterion = nn.MultiLabelSoftMarginLoss()\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-419c44d8953b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiLabelSoftMarginLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPG5hIuOZcO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the Classifier\n",
        "NUM_EPOCHS = 25\n",
        "TEST_FREQUENCY = 5\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    print(\"Starting epoch number \" + str(epoch))\n",
        "    train_loss = train_classifier(train_loader, classifier, criterion, optimizer)\n",
        "    print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n",
        "    if(epoch%TEST_FREQUENCY==0):\n",
        "        mAP_val, val_loss, _ = test_classifier(val_loader, classifier, criterion)\n",
        "        print('Evaluating classifier')\n",
        "        print(\"Mean Precision Score for Testing on Epoch \" +str(epoch) + \" is \"+ str(mAP_val))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr3QbGwOZcO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the classifier network\n",
        "torch.save(classifier.state_dict(), './voc_classifier.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}